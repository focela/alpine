#!/command/with-contenv bash
#-----------------------------------------------------------------------------
# Logging Configuration Script
#
# Purpose: Configures log rotation and log shipping (Fluent Bit) for container logging
# Context: Runs in s6-overlay initialization sequence (05-logging)
# Note: Handles both logrotate setup with multiple compression types and comprehensive
#       Fluent Bit configuration for log aggregation with multiple output backends
#-----------------------------------------------------------------------------

#-----------------------------------------------------------------------------
# CONFIGURATION - FRAMEWORK SETUP
#-----------------------------------------------------------------------------
# Load the core container framework library for utility functions
source /assets/functions/00-container

# Configure logging context and disable debug output during execution
output_off

# Prepare service for logging setup (no single flag - supports both logrotate and logshipping)
prepare_service
PROCESS_NAME="logging"

#-----------------------------------------------------------------------------
# PHASE 1: LOG ROTATION CONFIGURATION
#-----------------------------------------------------------------------------
# Configure logrotate for automatic log file rotation and compression
if var_true "${CONTAINER_ENABLE_LOGROTATE}" ; then
  print_debug "Enabling log rotation"

  #---------------------------------------------------------------------------
  # COMPRESSION TYPE CONFIGURATION
  #---------------------------------------------------------------------------
  # Configure compression based on LOGROTATE_COMPRESSION_TYPE
  # Supports: bzip2, gzip, zstd, none
  case "${LOGROTATE_COMPRESSION_TYPE,,}" in
    bz* )
      # Bzip2 compression - higher compression ratio, slower
      logrotate_compression=$(cat<<EOF
compress
compresscmd $(which bzip2)
compressext .bz2
compressoptions -${LOGROTATE_COMPRESSION_VALUE} ${LOGROTATE_COMPRESSION_EXTRA_PARAMETERS}
EOF
      )
    ;;
    gz* )
      # Gzip compression - balanced compression and speed
      logrotate_compression=$(cat<<EOF
compress
compresscmd $(which gzip)
compressext .gz
compressoptions -${LOGROTATE_COMPRESSION_VALUE} ${LOGROTATE_COMPRESSION_EXTRA_PARAMETERS}
EOF
      )
    ;;
    none )
      # No compression - fastest, largest files
      logrotate_compression=""
    ;;
    zs* )
      # Zstandard compression - modern, fast compression with good ratios
      logrotate_compression=$(cat<<EOF
compress
compresscmd $(which zstd)
compressext .zst
compressoptions -${LOGROTATE_COMPRESSION_VALUE} ${LOGROTATE_COMPRESSION_EXTRA_PARAMETERS}
EOF
      )
    ;;
  esac

  #---------------------------------------------------------------------------
  # LOGROTATE CONFIGURATION FILE GENERATION
  #---------------------------------------------------------------------------
  # Generate main logrotate configuration file
  cat <<EOF > /etc/logrotate.conf
daily
rotate ${LOGROTATE_RETAIN_DAYS}
copytruncate
dateext
nomail
notifempty
${logrotate_compression}
include /etc/logrotate.d
EOF

  # Set appropriate permissions for logrotate configuration
  chmod 0744 /etc/logrotate.conf

  # Create scheduling directory and add logrotate cron job
  mkdir -p "${CONTAINER_SCHEDULING_LOCATION}"

  # Schedule logrotate to run daily at 23:59 (11:59 PM)
  cat <<EOF > "${CONTAINER_SCHEDULING_LOCATION}"/logrotate
# Hardcoded in image in /etc/cont-init.d/$(basename "$0")
# Generated on $(TZ=${TIMEZONE} date +'%Y-%m-%d %H:%M:%S %Z')

59 23 * * * logrotate -f /etc/logrotate.conf >/dev/null 2>&1
EOF
fi

#-----------------------------------------------------------------------------
# PHASE 2: LOG SHIPPING CONFIGURATION
#-----------------------------------------------------------------------------
# Configure log shipping if enabled, otherwise stop the service
if var_false "${CONTAINER_ENABLE_LOGSHIPPING}" ; then
  service_stop "$(basename "$0")"
else

  #---------------------------------------------------------------------------
  # LOG SHIPPING BACKEND CONFIGURATION
  #---------------------------------------------------------------------------
  case "${CONTAINER_LOGSHIPPING_BACKEND,,}" in
    "fluent-bit" | "fluentbit" )

      #-----------------------------------------------------------------------
      # PLATFORM COMPATIBILITY VALIDATION
      #-----------------------------------------------------------------------
      # Validate OS and architecture compatibility for Fluent Bit
      os=$(cat /etc/os-release |grep ^ID= | cut -d = -f2)

      case ${os,,} in
        "alpine" )
          # Alpine Linux - check architecture and version compatibility
          archit="$(apk --print-arch)"
          case "$archit" in
            x86_64)
              # Check Alpine version - requires 3.11 or higher
              osver=$(cat /etc/os-release | grep VERSION_ID | cut -d = -f 2 | cut -d . -f 2 | cut -d _ -f 1)
              if [ "${osver}" -ge 11 ] || [ "$osver" = "edge" ] || [ "$osver" = "17*" ]; then
                :
              else
                print_error "Sorry this functionality is not available on < Alpine 3.11 releases"
                service_stop "$(basename "$0")"
                liftoff
                exit 0
              fi
            ;;
            *)
              print_error "Sorry this functionality is not available on ${archit} architecture"
              service_stop "$(basename "$0")"
              liftoff
              exit
            ;;
          esac
        ;;
        "debian" | "ubuntu" )
          # Debian/Ubuntu - check architecture compatibility
          archit=$(dpkg --print-architecture) && \
          case "$archit" in \
            amd64)
              :
            ;;
            *)
              print_error "Sorry this functionality is not available on ${archit} architecture"
              service_stop "$(basename "$0")"
              liftoff
              exit
            ;;
          esac
        ;;
      esac

      #-----------------------------------------------------------------------
      # FLUENT BIT CONFIGURATION SETUP
      #-----------------------------------------------------------------------
      # Configure Fluent Bit if auto setup is enabled
      if [ "${FLUENTBIT_SETUP_TYPE,,}" = "auto" ] ; then
        print_debug "[logship] Configuring Fluent-bit agent"

        # Convert boolean environment variables to on/off format for Fluent Bit
        truefalse_onoff FLUENTBIT_ENABLE_HTTP_SERVER
        truefalse_onoff FLUENTBIT_ENABLE_STORAGE_METRICS
        truefalse_onoff FLUENTBIT_STORAGE_CHECKSUM

        # Create required directories
        mkdir -p "${FLUENTBIT_STORAGE_PATH}"
        mkdir -p "${FLUENTBIT_LOG_PATH}"
        mkdir -p /etc/fluent-bit/conf.d

        # Create dummy configuration to prevent Fluent Bit startup failures
        # This ensures Fluent Bit has at least one valid input/output configuration
        cat <<EOF > /etc/fluent-bit/conf.d/do_not_delete.conf
# Don't delete this configuration file otherwise execution of fluent-bit will fail. It will not affect operation of your system or impact resources
[INPUT]
    Name   dummy
    Tag    ignore

[FILTER]
    Name grep
    Match ignore
    regex ignore ignore

[OUTPUT]
    Name   NULL
    Match  ignore
EOF

        #---------------------------------------------------------------------
        # CUSTOM PARSERS DETECTION
        #---------------------------------------------------------------------
        # Detect and include custom parser configurations
        if [ "$(ls -A /etc/fluent-bit/parsers.d/)" ]; then
          shopt -s nullglob
          for custom_parser in /etc/fluent-bit/parsers.d/*.conf ; do
            print_debug "[logship] Found additional parser for '$(echo "${custom_parser,,}" | sed "s|.conf||g")'"
            additional_parsers=$(echo "${additional_parsers}" ; cat<<EOF
    parsers_file ${custom_parser}
EOF
            )
          done
          shopt -u nullglob
        fi

        #---------------------------------------------------------------------
        # MAIN FLUENT BIT CONFIGURATION FILE
        #---------------------------------------------------------------------
        # Generate main Fluent Bit configuration with service settings
        cat <<EOF > /etc/fluent-bit/fluent-bit.conf
## Generated on $(TZ=${TIMEZONE} date +'%Y-%m-%d %H:%M:%S %Z')

@INCLUDE conf.d/*.conf
[SERVICE]
    daemon       Off
    flush        ${FLUENTBIT_FLUSH_SECONDS}
    grace        ${FLUENTBIT_GRACE_SECONDS}
    http_listen  ${FLUENTBIT_HTTP_LISTEN_IP}
    http_port    ${FLUENTBIT_HTTP_LISTEN_PORT}
    http_server  ${FLUENTBIT_ENABLE_HTTP_SERVER}
    log_file     ${FLUENTBIT_LOG_PATH}/${FLUENTBIT_LOG_FILE}
    log_level    ${FLUENTBIT_LOG_LEVEL}
    plugins_file ${FLUENTBIT_CONFIG_PLUGINS}
    storage.backlog.mem_limit ${FLUENTBIT_STORAGE_BACKLOG_LIMIT}
    storage.checksum ${FLUENTBIT_STORAGE_CHECKSUM}
    storage.metrics ${FLUENTBIT_ENABLE_STORAGE_METRICS}
    storage.path ${FLUENTBIT_STORAGE_PATH}
    storage.sync ${FLUENTBIT_STORAGE_SYNC}
    parsers_file ${FLUENTBIT_CONFIG_PARSERS}
${additional_parsers}
EOF

        #---------------------------------------------------------------------
        # INPUT PLUGIN CONFIGURATION - MODE SELECTION
        #---------------------------------------------------------------------
        # Configure input plugins based on Fluent Bit mode
        case "${FLUENTBIT_MODE,,}" in
          "normal" )
            print_debug "[logship] Configuring Fluent-Bit for Normal/Client mode"

            #-----------------------------------------------------------------
            # TAIL INPUT PLUGIN CONFIGURATION
            #-----------------------------------------------------------------
            # Configure optional tail plugin parameters
            if var_true "${FLUENTBIT_TAIL_KEY_PATH_ENABLE}" ; then
              tail_key_path="    Path_Key          ${FLUENTBIT_TAIL_KEY_PATH}"
            fi

            if var_true "${FLUENTBIT_TAIL_KEY_OFFSET_ENABLE}" ; then
              tail_key_offset="    Offset_Key        ${FLUENTBIT_TAIL_KEY_OFFSET}"
            fi

            if [ -n "${FLUENTBIT_TAIL_IGNORE_OLDER}" ] ; then
              tail_ignore_older="    Ignore_Older      ${FLUENTBIT_TAIL_IGNORE_OLDER}"
            fi

            # Convert boolean settings for tail plugin
            truefalse_onoff FLUENTBIT_TAIL_SKIP_EMPTY_LINES
            truefalse_onoff FLUENTBIT_TAIL_SKIP_LONG_LINES

            #-----------------------------------------------------------------
            # PHASE 1: RUNTIME LOGSHIP_* ENVIRONMENT VARIABLE PROCESSING
            #-----------------------------------------------------------------
            # Process LOGSHIP_* environment variables from runtime configuration
            # These define which log files to ship and monitor
            print_debug "[logship] Processing runtime LOGSHIP_* environment variables"

            # Create temporary file to store extracted logship environment variables
            logshipenv=$(mktemp)

            # Extract all LOGSHIP_* variables and remove LOGSHIP_ prefix
            set -o posix; set -f
            set | grep -E '^LOGSHIP_'| sed "s|LOGSHIP_||g" > "${logshipenv}"

            # Process each logship entry from runtime variables
            while IFS= read -r logship_entry; do
              logship_title="$(echo "${logship_entry}" | cut -d = -f1 | tr '[:upper:]' '[:lower:]' )"
              logship_value="$(echo "${logship_entry}" | cut -d = -f2 )"

              # Remove surrounding quotes from value
              logship_value="$(echo "${logship_value:1:-1}")"

              # Handle disabled/false logship entries
              if var_false "${logship_value}" ; then
                print_debug "[logship] Disabling ${logship_title} Log Shipping"

                # Create disabled/nulled logship configuration
                cat <<EOF > "/etc/fluent-bit/conf.d/in_tail_${logship_title,,}.conf"
# Nulled Log Monitoring of ${logship_title}  generated by Environment Variable defined in Image build, or Runtime argument
# Generated on $(TZ=${TIMEZONE} date +'%Y-%m-%d %H:%M:%S %Z')
EOF

                # Update logrotate configuration to skip this log if it exists
                if [ -f "/assets/logrotate/${logship_title,,}" ] ; then
                  print_debug "[logship] Setting Logrotate value to skip for /assets/logrotate/${logship_title,,}"
                  sed -i "# logship: .*|# logship: ignore"
                fi
              else
                print_debug "[logship] Adding ${logship_title} with to be parsed by ${CONTAINER_LOGSHIPPING_BACKEND}"

                # Configure database tracking for tail plugin if enabled
                if var_true "${FLUENTBIT_TAIL_DB_ENABLE}" ; then
                  tail_db=$(cat<<EOF
    DB                $(dirname ${logship_value})/.$(basename ${logship_value}).db
    DB.sync           ${FLUENTBIT_TAIL_DB_SYNC}
    DB.locking        ${FLUENTBIT_TAIL_DB_LOCK}
    DB.journal_mode   ${FLUENTBIT_TAIL_DB_JOURNAL_MODE}
EOF
                  )
                fi

                # Create active tail input configuration for this log file
                cat <<EOF > "/etc/fluent-bit/conf.d/in_tail_${logship_title,,}.conf"
# Log File Monitoring created automatically generated by Environment Variable defined in Image build, or Runtime argument
# Entered Value: ${logship_value}
# Generated on $(TZ=${TIMEZONE} date +'%Y-%m-%d %H:%M:%S %Z')

[INPUT]
    Name              tail
    Path              ${logship_value}
    Tag               ${logship_title,,}
    Buffer_Chunk_Size ${FLUENTBIT_TAIL_BUFFER_CHUNK_SIZE}
    Buffer_Max_Size   ${FLUENTBIT_TAIL_BUFFER_MAX_SIZE}
    Read_from_Head    ${FLUENTBIT_TAIL_READ_FROM_HEAD}
    Skip_Empty_Lines  ${FLUENTBIT_TAIL_SKIP_EMPTY_LINES}
    Skip_Long_Lines   ${FLUENTBIT_TAIL_SKIP_LONG_LINES}
${tail_key_path}
${tail_db}
${tail_ignore_older}
${tail_key_offset}

[FILTER]
    Name record_modifier
    Match ${logship_title,,}
    Record hostname $(hostname)
    Record container_name ${CONTAINER_NAME}
    Record product ${logship_title,,}

EOF
              fi
            done < "${logshipenv}"

            # Cleanup temporary file and variables
            rm -rf "$logshipenv"
            set +f
            unset logshipenv logship_entry logship_value logship_title db
            unset "${!LOGSHIP_@}"

            #-----------------------------------------------------------------
            # PHASE 2: DEFAULT CONFIGURATION FILE PROCESSING
            #-----------------------------------------------------------------
            # Process LOGSHIP_* variables from default configuration files
            # These provide fallback log shipping configurations
            print_debug "[logship] Processing default configuration files for LOGSHIP_* variables"

            # Iterate through all default configuration files
            for d in /assets/defaults/* ; do
              if [ "$d" != "/assets/defaults/00-container" ] ; then
                print_debug "[logship] Processing default file: ${d}"

                # Source the default file to load its variables
                # shellcheck source=/assets/defaults/
                source "$d"

                # Create temporary file for this default file's logship variables
                logshipenv=$(mktemp)

                # Extract LOGSHIP_* variables from this default file
                set -o posix; set -f
                set | grep -E '^LOGSHIP_'| sed "s|LOGSHIP_||g" > "${logshipenv}"

                # Process each logship entry from this default file
                while IFS= read -r logship_entry; do
                  logship_title="$(echo "${logship_entry}" | cut -d = -f1 | tr '[:upper:]' '[:lower:]')"
                  logship_value="$(echo "${logship_entry}" | cut -d = -f2 )"

                  # Remove surrounding quotes from value
                  logship_value="$(echo "${logship_value:1:-1}")"

                  # Configure database tracking for tail plugin if enabled
                  if var_true "${FLUENTBIT_TAIL_DB_ENABLE}" ; then
                    tail_db=$(cat<<EOF
    DB                $(dirname ${logship_value})/.$(basename ${logship_value}).db
    DB.sync           ${FLUENTBIT_TAIL_DB_SYNC}
    DB.locking        ${FLUENTBIT_TAIL_DB_LOCK}
    DB.journal_mode   ${FLUENTBIT_TAIL_DB_JOURNAL_MODE}
EOF
                    )
                  fi

                  # Only create logship file if it doesn't already exist (runtime vars take precedence)
                  if [ ! -f "/etc/fluent-bit/conf.d/in_tail_${logship_title,,}.conf" ] ; then
                    print_debug "[logship] Adding ${logship_title} with to parsed by ${CONTAINER_LOGSHIPPING_BACKEND}"

                    # Create tail input configuration from default file
                    cat <<EOF > "/etc/fluent-bit/conf.d/in_tail_${logship_title,,}.conf"
# Log File Shipping created automatically generated by reading through defaults in /assets/defaults/*
# Entered Value: ${logship_value}
# Generated on $(TZ=${TIMEZONE} date +'%Y-%m-%d %H:%M:%S %Z')

[INPUT]
    Name              tail
    Path              ${logship_value}
    Tag               ${CONTAINER_NAME}_${logship_title,,}
    Buffer_Chunk_Size ${FLUENTBIT_TAIL_BUFFER_CHUNK_SIZE}
    Buffer_Max_Size   ${FLUENTBIT_TAIL_BUFFER_MAX_SIZE}
    Read_from_Head    ${FLUENTBIT_TAIL_READ_FROM_HEAD}
    Skip_Empty_Lines  ${FLUENTBIT_TAIL_SKIP_EMPTY_LINES}
    Skip_Long_Lines   ${FLUENTBIT_TAIL_SKIP_LONG_LINES}
${tail_key_path}
${tail_db}
${tail_ignore_older}
${tail_key_offset}
EOF
                  else
                    print_debug "[logship] Skipping adding ${logship_title} as it already exists"
                  fi
                done < "${logshipenv}"

                # Cleanup for this iteration
                rm -rf "$logshipenv"
                set +f
                unset logshipenv logship_entry logship_value logship_title
                unset "${!LOGSHIP_@}"
              fi
            done
          ;;

          "proxy" | "forward" )
            print_debug "[logship] Configuring Fluent-Bit for Proxy/Forwarding Mode"

            # Configure forward input for proxy/aggregation mode
            # This mode receives logs from other Fluent Bit instances
            cat <<EOF > /etc/fluent-bit/conf.d/in_forward.conf
[INPUT]
    Name forward
    Listen 0.0.0.0
    Port ${FLUENTBIT_FORWARD_PORT}
    Buffer_Chunk_Size ${FLUENTBIT_FORWARD_BUFFER_CHUNK_SIZE}
    Buffer_Max_Size   ${FLUENTBIT_FORWARD_BUFFER_MAX_SIZE}
EOF
          ;;
        esac

        #---------------------------------------------------------------------
        # OUTPUT PLUGIN CONFIGURATION
        #---------------------------------------------------------------------
        # Configure output plugins based on selected backend
        case "${FLUENTBIT_OUTPUT,,}" in
          "loki" )
            print_debug "[logship] Configuring Loki output plugin"

            # Transform file-based variables for Loki configuration
            transform_file_var \
                            FLUENTBIT_OUTPUT_LOKI_HOST \
                            FLUENTBIT_OUTPUT_LOKI_PORT \
                            FLUENTBIT_OUTPUT_LOKI_USER \
                            FLUENTBIT_OUTPUT_LOKI_PASS \
                            FLUENTBIT_OUTPUT_LOKI_TENANT_ID

            # Configure optional authentication parameters
            if [ -n "${FLUENTBIT_OUTPUT_LOKI_USER}" ] ; then
              loki_user="    http_user              ${FLUENTBIT_OUTPUT_LOKI_USER}"
            fi

            if [ -n "${FLUENTBIT_OUTPUT_LOKI_PASS}" ] ; then
              loki_pass="    http_passwd            ${FLUENTBIT_OUTPUT_LOKI_PASS}"
            fi

            if [ -n "${FLUENTBIT_OUTPUT_LOKI_TENANT_ID}" ] ; then
              loki_tenant_id="    tenant_id              ${FLUENTBIT_OUTPUT_LOKI_TENANT_ID}"
            fi

            # Convert boolean settings for Loki plugin
            truefalse_onoff FLUENTBIT_OUTPUT_LOKI_TLS
            truefalse_onoff FLUENTBIT_OUTPUT_LOKI_TLS_VERIFY
            truefalse_onoff FLUENTBIT_OUTPUT_LOKI_COMPRESS_GZIP

            # Generate Loki output configuration
            cat <<EOF > /etc/fluent-bit/conf.d/out_loki.conf
## Auto generated LOKI Output plugin for Fluent Bit
## Generated on $(TZ=${TIMEZONE} date +'%Y-%m-%d %H:%M:%S %Z')

[OUTPUT]
    name                   loki
    match                  *
    host                   ${FLUENTBIT_OUTPUT_LOKI_HOST}
    port                   ${FLUENTBIT_OUTPUT_LOKI_PORT}
    tls                    ${FLUENTBIT_OUTPUT_LOKI_TLS,,}
    tls.verify             ${FLUENTBIT_OUTPUT_LOKI_TLS_VERIFY,,}
    compress               ${FLUENTBIT_OUTPUT_LOKI_COMPRESS_GZIP,,}
    labels                 logshipper=${CONTAINER_NAME}
    Label_keys             \$hostname,\$container_name,\$product
${loki_user}
${loki_pass}
${loki_tenant_id}

EOF
          ;;

          "fluentd" | "forward" )
            print_debug "[logship] Configuring FluentD forward output plugin"

            # Convert boolean settings for forward plugin
            truefalse_onoff FLUENTBIT_OUTPUT_FORWARD_TLS
            truefalse_onoff FLUENTBIT_OUTPUT_FORWARD_TLS_VERIFY

            # Configure optional shared key authentication
            if [ ! -z "${FLUENTBIT_OUTPUT_FORWARD_SECRET}" ] ; then
              forward_secret="    Shared_Key    ${FLUENTBIT_OUTPUT_FORWARD_SECRET}"
            fi

            # Transform file-based variables for forward configuration
            transform_file_var FLUENTBIT_OUTPUT_FORWARD_HOST

            # Generate FluentD forward output configuration
            cat <<EOF > /etc/fluent-bit/conf.d/out_forward.conf
## Auto generated FluentD Forward Output plugin for Fluent Bit
## Generated on $(TZ=${TIMEZONE} date +'%Y-%m-%d %H:%M:%S %Z')

[OUTPUT]
    Name          forward
    Match         *
    Host          ${FLUENTBIT_OUTPUT_FORWARD_HOST}
    Port          ${FLUENTBIT_FORWARD_PORT}
    Self_Hostname ${CONTAINER_NAME}
    tls           ${FLUENTBIT_OUTPUT_FORWARD_TLS,,}
    tls.verify    ${FLUENTBIT_OUTPUT_FORWARD_TLS_VERIFY,,}
${forward_secret}
EOF
          ;;

          "null" )
            print_debug "[logship] Configuring null output plugin (discard logs)"

            # Generate null output configuration (discards all logs)
            cat <<EOF > /etc/fluent-bit/conf.d/out_null.conf
## Auto generated NULL Output plugin for Fluent Bit
## Generated on $(TZ=${TIMEZONE} date +'%Y-%m-%d %H:%M:%S %Z')

[OUTPUT]
    Name null
    Match *
EOF
          ;;
        esac
      else
        #---------------------------------------------------------------------
        # MANUAL CONFIGURATION MODE
        #---------------------------------------------------------------------
        # Provide minimal configuration for manual setup
        print_notice "[logship] Not auto configuring Fluent-Bit. Drop configuration files in /etc/fluent-bit/conf.d"

        # Create basic configuration file that includes custom configurations
        cat <<EOF > /etc/fluent-bit/fluent-bit.conf
## This configuration file allows you to put your own configuration in /etc/fluent-bit/conf.d - Don't delete or it will fail :)
## Generated on $(TZ=${TIMEZONE} date +'%Y-%m-%d %H:%M:%S %Z')
@INCLUDE conf.d/*.conf
EOF
      fi

      #-----------------------------------------------------------------------
      # INTEGRATION SETUP
      #-----------------------------------------------------------------------
      # Setup log rotation for Fluent Bit logs
      create_logrotate fluentbit "${FLUENTBIT_LOG_PATH}"/"${FLUENTBIT_LOG_FILE}"

      # Integrate with Zabbix monitoring if enabled
      if var_true "${CONTAINER_ENABLE_MONITORING}" && [ "${CONTAINER_MONITORING_BACKEND,,}" = "zabbix" ]; then
        cat <<EOF > "${ZABBIX_CONFIG_PATH}"/"${ZABBIX_CONFIG_FILE}".d/focela-fluentbit.conf
# Zabbix Fluentbit Configuration - Automatically generated based on container startup options
# Find Companion Zabbix Server Templates at https://github.com/focela/docker-alpine or https://github.com/focela/docker-debian
# Autoregister=fluentbit
EOF
      fi

      print_notice "Container configured to ship logs via '${CONTAINER_LOGSHIPPING_BACKEND}'"
    ;;

    #-------------------------------------------------------------------------
    # UNSUPPORTED LOG SHIPPING BACKENDS
    #-------------------------------------------------------------------------
    *)
      print_error "[logship] Unknown Log Shipping Backend"
      exit 1
    ;;
  esac
fi

#-----------------------------------------------------------------------------
# FINALIZATION
#-----------------------------------------------------------------------------
# Mark this initialization script as completed in container state tracking
liftoff

# Re-enable output for subsequent initialization scripts
output_on
